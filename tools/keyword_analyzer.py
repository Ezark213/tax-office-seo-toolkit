#!/usr/bin/env python3
"""
ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰åˆ†æãƒ„ãƒ¼ãƒ«
åœ°åŸŸÃ—ç¨ç†å£«æ¥­ç•Œã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰åˆ†æã‚’å®Ÿè¡Œ
"""

import click
import pandas as pd
from typing import List, Dict, Optional
import requests
import time
import json
from pathlib import Path
import sys
import os

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®ãƒ«ãƒ¼ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ãƒ‘ã‚¹ã«è¿½åŠ 
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from config.keyword_database import (
    LOCATION_KEYWORDS, SERVICE_KEYWORDS, SEASONAL_KEYWORDS,
    get_location_service_combinations, get_target_keywords_for_office
)
from config.office_settings import TARGET_AREAS, MAIN_SERVICES

class KeywordAnalyzer:
    """ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰åˆ†æã‚¯ãƒ©ã‚¹"""
    
    def __init__(self, api_key: Optional[str] = None):
        """
        åˆæœŸåŒ–
        
        Args:
            api_key: Google Keyword Planner API key (ã‚ªãƒ—ã‚·ãƒ§ãƒ³)
        """
        self.api_key = api_key
        self.results = {}
    
    def analyze_location_keywords(self, location: str, services: List[str] = None) -> Dict:
        """
        åœ°åŸŸã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã®åˆ†æ
        
        Args:
            location: å¯¾è±¡åœ°åŸŸ
            services: å¯¾è±¡ã‚µãƒ¼ãƒ“ã‚¹ä¸€è¦§
            
        Returns:
            åˆ†æçµæœè¾æ›¸
        """
        if services is None:
            services = MAIN_SERVICES
        
        print(f"ğŸ” {location}ã®ç¨ç†å£«æ¥­ç•Œã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰åˆ†æã‚’é–‹å§‹...")
        
        # åŸºæœ¬ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ç”Ÿæˆ
        primary_keywords = [
            f"{location} ç¨ç†å£«",
            f"{location} ä¼šè¨ˆäº‹å‹™æ‰€", 
            f"{location} å…¬èªä¼šè¨ˆå£«",
            f"ç¨ç†å£« {location}",
            f"ä¼šè¨ˆå£« {location}"
        ]
        
        # ã‚µãƒ¼ãƒ“ã‚¹åˆ¥ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰
        service_keywords = []
        for service in services:
            service_keywords.extend([
                f"{location} {service}",
                f"{service} {location}",
                f"{location} {service} ç›¸è«‡",
                f"{location} {service} æ–™é‡‘"
            ])
        
        # ãƒ­ãƒ³ã‚°ãƒ†ãƒ¼ãƒ«ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰
        long_tail_keywords = []
        for service in services:
            long_tail_keywords.extend([
                f"{location} {service} ãŠã™ã™ã‚",
                f"{location} {service} å®‰ã„",
                f"{location} {service} è©•åˆ¤",
                f"{location} {service} æ¯”è¼ƒ"
            ])
        
        results = {
            "location": location,
            "primary_keywords": primary_keywords,
            "service_keywords": service_keywords,
            "long_tail_keywords": long_tail_keywords,
            "total_keywords": len(primary_keywords) + len(service_keywords) + len(long_tail_keywords)
        }
        
        # æ¤œç´¢ãƒœãƒªãƒ¥ãƒ¼ãƒ æ¨å®šï¼ˆãƒ¢ãƒƒã‚¯ãƒ‡ãƒ¼ã‚¿ï¼‰
        results["volume_estimates"] = self._estimate_search_volumes(
            primary_keywords + service_keywords[:10]
        )
        
        self.results[location] = results
        return results
    
    def _estimate_search_volumes(self, keywords: List[str]) -> Dict[str, int]:
        """
        æ¤œç´¢ãƒœãƒªãƒ¥ãƒ¼ãƒ æ¨å®šï¼ˆãƒ¢ãƒƒã‚¯ãƒ‡ãƒ¼ã‚¿ï¼‰
        å®Ÿéš›ã®å®Ÿè£…ã§ã¯ Google Ads API ã‚„ä»–ã®ãƒ„ãƒ¼ãƒ«ã‚’ä½¿ç”¨
        """
        volumes = {}
        
        for keyword in keywords:
            # åœ°åŸŸè¦æ¨¡ã«ã‚ˆã‚‹åŸºæœ¬ãƒœãƒªãƒ¥ãƒ¼ãƒ è¨­å®š
            base_volume = 100
            
            # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚¿ã‚¤ãƒ—ã«ã‚ˆã‚‹èª¿æ•´
            if "ç¨ç†å£«" in keyword and any(area in keyword for area in ["æµå±±", "æŸ", "æ¾æˆ¸"]):
                base_volume = 200
            elif "ç¢ºå®šç”³å‘Š" in keyword:
                base_volume = 300
            elif "ä¼šç¤¾è¨­ç«‹" in keyword:
                base_volume = 150
            elif "ç›¸è«‡" in keyword:
                base_volume = 80
            elif "æ–™é‡‘" in keyword or "è²»ç”¨" in keyword:
                base_volume = 120
            
            # ãƒ©ãƒ³ãƒ€ãƒ ãªå¤‰å‹•ã‚’è¿½åŠ ï¼ˆå®Ÿéš›ã®ãƒ‡ãƒ¼ã‚¿ã®ãƒãƒ©ã¤ãã‚’æ¨¡æ“¬ï¼‰
            import random
            variation = random.randint(-30, 50)
            volumes[keyword] = max(10, base_volume + variation)
        
        return volumes
    
    def analyze_competitor_keywords(self, competitor_urls: List[str]) -> Dict:
        """
        ç«¶åˆã‚µã‚¤ãƒˆã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰åˆ†æ
        
        Args:
            competitor_urls: ç«¶åˆã‚µã‚¤ãƒˆã®URLä¸€è¦§
            
        Returns:
            ç«¶åˆåˆ†æçµæœ
        """
        print("ğŸ” ç«¶åˆã‚µã‚¤ãƒˆã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰åˆ†æ...")
        
        competitor_data = {}
        
        for url in competitor_urls:
            print(f"  ğŸ“Š åˆ†æä¸­: {url}")
            
            # å®Ÿéš›ã®å®Ÿè£…ã§ã¯ã€SEOãƒ„ãƒ¼ãƒ«ã®APIã‚„ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ã‚’ä½¿ç”¨
            # ã“ã“ã§ã¯ãƒ¢ãƒƒã‚¯ãƒ‡ãƒ¼ã‚¿ã‚’è¿”ã™
            competitor_data[url] = {
                "estimated_keywords": random.randint(50, 200),
                "estimated_traffic": random.randint(500, 2000),
                "top_keywords": [
                    f"æµå±±å¸‚ ç¨ç†å£«",
                    f"åƒè‘‰çœŒ ç¢ºå®šç”³å‘Š", 
                    f"ä¼šç¤¾è¨­ç«‹ æµå±±",
                    f"ç¨å‹™ç›¸è«‡ æŸå¸‚"
                ],
                "content_gaps": [
                    "ITä¼æ¥­å‘ã‘ç¨å‹™",
                    "ã‚¹ã‚¿ãƒ¼ãƒˆã‚¢ãƒƒãƒ—æ”¯æ´",
                    "ç›¸ç¶šç¨å°‚é–€"
                ]
            }
            
            time.sleep(1)  # APIåˆ¶é™å¯¾ç­–
        
        return competitor_data
    
    def generate_content_keywords(self, month: int = None) -> List[str]:
        """
        ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ä½œæˆç”¨ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ç”Ÿæˆ
        
        Args:
            month: å¯¾è±¡æœˆï¼ˆ1-12ï¼‰
            
        Returns:
            ã‚³ãƒ³ãƒ†ãƒ³ãƒ„å‘ã‘ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ä¸€è¦§
        """
        print("ğŸ“ ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ä½œæˆç”¨ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ç”Ÿæˆ...")
        
        content_keywords = []
        
        # åŸºæœ¬çš„ãªè§£èª¬ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰
        basic_content = [
            "ç¢ºå®šç”³å‘Š ã‚„ã‚Šæ–¹",
            "é’è‰²ç”³å‘Š ç™½è‰²ç”³å‘Š é•ã„", 
            "ä¼šç¤¾è¨­ç«‹ æ‰‹é †",
            "å€‹äººäº‹æ¥­ä¸» ç¨é‡‘",
            "æ³•äººç¨ è¨ˆç®—æ–¹æ³•",
            "çµŒè²» ç¯„å›²",
            "æ§é™¤ ç¨®é¡",
            "ç¨å‹™èª¿æŸ» å¯¾ç­–"
        ]
        content_keywords.extend(basic_content)
        
        # æœˆåˆ¥ãƒ»å­£ç¯€ã‚³ãƒ³ãƒ†ãƒ³ãƒ„
        if month:
            seasonal = SEASONAL_KEYWORDS.get(f"{month}æœˆ", [])
            for item in seasonal:
                content_keywords.extend([
                    f"{item} ã¨ã¯",
                    f"{item} æ‰‹ç¶šã",
                    f"{item} æ³¨æ„ç‚¹",
                    f"{item} æœŸé™"
                ])
        
        # åœ°åŸŸå¯†ç€ã‚³ãƒ³ãƒ†ãƒ³ãƒ„
        for area in TARGET_AREAS[:3]:  # ä¸Šä½3åœ°åŸŸ
            content_keywords.extend([
                f"{area} ç¨ç†å£« é¸ã³æ–¹",
                f"{area} é–‹æ¥­ æ‰‹ç¶šã",
                f"{area} ä¼šè¨ˆäº‹å‹™æ‰€ æ¯”è¼ƒ"
            ])
        
        return content_keywords
    
    def export_results(self, output_file: str = None) -> str:
        """
        åˆ†æçµæœã‚’ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ
        
        Args:
            output_file: å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
            
        Returns:
            å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
        """
        if not output_file:
            timestamp = time.strftime("%Y%m%d_%H%M%S")
            output_file = f"keyword_analysis_{timestamp}.json"
        
        output_path = Path("data/keywords") / output_file
        output_path.parent.mkdir(parents=True, exist_ok=True)
        
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(self.results, f, ensure_ascii=False, indent=2)
        
        print(f"âœ… åˆ†æçµæœã‚’ä¿å­˜: {output_path}")
        return str(output_path)

@click.command()
@click.option('--location', '-l', default='æµå±±å¸‚', help='å¯¾è±¡åœ°åŸŸ')
@click.option('--services', '-s', multiple=True, help='å¯¾è±¡ã‚µãƒ¼ãƒ“ã‚¹')
@click.option('--competitors', '-c', help='ç«¶åˆURLãƒªã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«')
@click.option('--month', '-m', type=int, help='å¯¾è±¡æœˆï¼ˆ1-12ï¼‰')
@click.option('--output', '-o', help='å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«å')
@click.option('--api-key', help='Google Ads API Key')
def main(location, services, competitors, month, output, api_key):
    """ç¨ç†å£«äº‹å‹™æ‰€å‘ã‘ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰åˆ†æãƒ„ãƒ¼ãƒ«"""
    
    print("ğŸš€ ç¨ç†å£«äº‹å‹™æ‰€å‘ã‘ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰åˆ†æãƒ„ãƒ¼ãƒ«")
    print("=" * 50)
    
    analyzer = KeywordAnalyzer(api_key)
    
    # ã‚µãƒ¼ãƒ“ã‚¹ä¸€è¦§ã®è¨­å®š
    if not services:
        services = MAIN_SERVICES
    else:
        services = list(services)
    
    print(f"ğŸ“ å¯¾è±¡åœ°åŸŸ: {location}")
    print(f"ğŸ› ï¸ å¯¾è±¡ã‚µãƒ¼ãƒ“ã‚¹: {', '.join(services)}")
    
    # åœ°åŸŸã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰åˆ†æ
    location_results = analyzer.analyze_location_keywords(location, services)
    
    print(f"\nğŸ“Š åˆ†æçµæœ:")
    print(f"  - ãƒ—ãƒ©ã‚¤ãƒãƒªã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰: {len(location_results['primary_keywords'])}å€‹")
    print(f"  - ã‚µãƒ¼ãƒ“ã‚¹é–¢é€£: {len(location_results['service_keywords'])}å€‹")
    print(f"  - ãƒ­ãƒ³ã‚°ãƒ†ãƒ¼ãƒ«: {len(location_results['long_tail_keywords'])}å€‹")
    print(f"  - åˆè¨ˆ: {location_results['total_keywords']}å€‹")
    
    # æ¤œç´¢ãƒœãƒªãƒ¥ãƒ¼ãƒ ä¸Šä½5ä½ã‚’è¡¨ç¤º
    volumes = location_results['volume_estimates']
    top_keywords = sorted(volumes.items(), key=lambda x: x[1], reverse=True)[:5]
    
    print(f"\nğŸ” æ¤œç´¢ãƒœãƒªãƒ¥ãƒ¼ãƒ ä¸Šä½:")
    for keyword, volume in top_keywords:
        print(f"  - {keyword}: {volume:,}/æœˆ")
    
    # ç«¶åˆåˆ†æï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
    if competitors:
        competitor_urls = []
        if Path(competitors).exists():
            with open(competitors, 'r') as f:
                competitor_urls = [line.strip() for line in f if line.strip()]
        
        if competitor_urls:
            competitor_results = analyzer.analyze_competitor_keywords(competitor_urls)
            analyzer.results['competitors'] = competitor_results
            
            print(f"\nğŸ¢ ç«¶åˆåˆ†æå®Œäº†: {len(competitor_urls)}ã‚µã‚¤ãƒˆ")
    
    # ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ç”Ÿæˆ
    content_keywords = analyzer.generate_content_keywords(month)
    analyzer.results['content_keywords'] = content_keywords
    
    print(f"\nğŸ“ ã‚³ãƒ³ãƒ†ãƒ³ãƒ„å‘ã‘ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰: {len(content_keywords)}å€‹ç”Ÿæˆ")
    
    # çµæœã‚’ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ
    output_file = analyzer.export_results(output)
    
    print(f"\nâœ… åˆ†æå®Œäº†ï¼")
    print(f"ğŸ“„ è©³ç´°çµæœ: {output_file}")
    
    # æ¬¡ã®ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ææ¡ˆ
    print(f"\nğŸ’¡ æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—:")
    print(f"  1. ç«¶åˆåˆ†æ: python tools/competitor_analysis.py")
    print(f"  2. ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ä½œæˆ: python tools/content_generator.py") 
    print(f"  3. é †ä½è¿½è·¡é–‹å§‹: python tools/rank_tracker.py --setup")

if __name__ == '__main__':
    import random
    main()